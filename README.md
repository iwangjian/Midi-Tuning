# Midi-Tuning

Paper: [*Instruct Once, Chat Consistently in Multiple Rounds*: An Efficient Tuning Framework for Dialogue](https://arxiv.org/abs/2402.06967) (ACL 2024)

We propose an efficient Multi-round Interactive Dialogue Tuning (Midi-Tuning) framework. It models the agent and user individually with two adapters built upon large language models. The adapters make use of respective utterances round by round in alternating order and they are tuned via a round-level memory caching mechanism.

<p align="center">
<img src="figure/overview.png" width="96%" />
</p>


## Requirements
```bash
pip install -r requirements.txt
```

## Datasets

Coming soon ...


## Quickstart

Coming soon ...